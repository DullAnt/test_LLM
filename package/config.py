"""
–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –≤–Ω–µ—à–Ω–∏—Ö —Å–µ—Ä–≤–∏—Å–æ–≤
"""
import os
from dataclasses import dataclass
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
from typing import Optional, Dict
import requests

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

EMBEDDING_MODELS = {
    "paraphrase-multilingual-MiniLM-L12-v2": {
        "dims": 384,
        "size": "420MB",
        "quality": "good",
        "description": "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è, –±—ã—Å—Ç—Ä–∞—è, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä—É—Å—Å–∫–æ–≥–æ"
    },
    "intfloat/multilingual-e5-large-instruct": {
        "dims": 1024,
        "size": "2.2GB",
        "quality": "excellent",
        "description": "–û—á–µ–Ω—å –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ"
    }
}


# ==========================================
# –ê–í–¢–û–û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –†–ê–ó–ú–ï–†–ù–û–°–¢–ò –ú–û–î–ï–õ–ò
# ==========================================


def get_model_dims_from_hf(model_name: str) -> Optional[int]:
    """–ü–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ HuggingFace API"""
    try:
        url = f"https://huggingface.co/{model_name}/resolve/main/config.json"
        print(f"üîç –ó–∞–ø—Ä–æ—Å –∫ HuggingFace API: {model_name}...")
        response = requests.get(url, timeout=10)
        
        if response.status_code == 200:
            config = response.json()
            
            possible_keys = [
                'hidden_size',
                'embedding_size',
                'd_model',
                'dim',
                'n_embd',
            ]
            
            for key in possible_keys:
                if key in config:
                    dims = config[key]
                    print(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –Ω–∞–π–¥–µ–Ω–∞: {dims} (–ø–æ–ª–µ: {key})")
                    return dims
            
            print(f" –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ config.json")
            return None
        else:
            print(f"  –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å config: HTTP {response.status_code}")
            return None
    except Exception as e:
        print(f" –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ HuggingFace: {e}")
        return None


def get_model_dims_from_model(model_name: str) -> Optional[int]:
    """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∑–∞–≥—Ä—É–∑–∏–≤ –º–æ–¥–µ–ª—å"""
    try:
        print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏...")
        model = SentenceTransformer(model_name)
        test_vec = model.encode("test", show_progress_bar=False)
        dims = len(test_vec)
        print(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞: {dims}")
        return dims
    except Exception as e:
        print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å: {e}")
        return None


def get_model_info(model_name: str) -> Dict:
    """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏ (dims + –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ)"""
    
    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤ —Å–ª–æ–≤–∞—Ä–µ
    if model_name in EMBEDDING_MODELS:
        print(f"–ú–æ–¥–µ–ª—å –Ω–∞–π–¥–µ–Ω–∞ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
        return EMBEDDING_MODELS[model_name]
    
    print(f"\n{'='*70}")
    print(f"–ú–æ–¥–µ–ª—å '{model_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ EMBEDDING_MODELS")
    print(f"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...")
    print(f"{'='*70}\n")
    
    # 2. –ü–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ API
    dims = get_model_dims_from_hf(model_name)
    
    # 3. –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å - –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    if dims is None:
        print(f"\n\API –Ω–µ –ø–æ–º–æ–≥, –∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å...")
        dims = get_model_dims_from_model(model_name)
    
    # 4. –î–µ—Ñ–æ–ª—Ç
    if dims is None:
        print(f"\n  –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏!")
        print(f"  –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è dims=384 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
        dims = 384
    
    model_info = {
        "dims": dims,
        "size": "unknown",
        "quality": "unknown",
        "description": f"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ (dims={dims})"
    }
    
    EMBEDDING_MODELS[model_name] = model_info
    
    print(f"\n{'='*70}")
    print(f" –ú–æ–¥–µ–ª—å –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ –∫–µ—à: {model_name}")
    print(f"   –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {dims}")
    print(f"{'='*70}\n")
    
    return model_info

# –ö–û–ù–°–¢–ê–ù–¢–´ (–ï–î–ò–ù–°–¢–í–ï–ù–ù–û–ï –ú–ï–°–¢–û –û–ü–†–ï–î–ï–õ–ï–ù–ò–Ø)

# Embedding –º–æ–¥–µ–ª—å 
DEFAULT_EMBEDDING_MODEL = os.getenv(
    "EMBEDDING_MODEL",
    # "google/embeddinggemma-300m"
    "intfloat/multilingual-e5-large"
)


HF_TOKEN = os.getenv("HUGGINGFACE_TOKEN")
if HF_TOKEN:
    os.environ["HF_TOKEN"] = HF_TOKEN

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
print(f"\n{'='*70}")
print(f"–ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø EMBEDDING –ú–û–î–ï–õ–ò")
print(f"{'='*70}")

model_info = get_model_info(DEFAULT_EMBEDDING_MODEL)
DEFAULT_EMBEDDING_DIMS = model_info["dims"]

print(f"–ú–æ–¥–µ–ª—å: {DEFAULT_EMBEDDING_MODEL}")
print(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {DEFAULT_EMBEDDING_DIMS}")
if model_info["size"] != "unknown":
    print(f"–†–∞–∑–º–µ—Ä: {model_info['size']}")
if model_info["quality"] != "unknown":
    print(f"–ö–∞—á–µ—Å—Ç–≤–æ: {model_info['quality']}")
print(f"{'='*70}\n")

# Ollama –º–æ–¥–µ–ª—å 
DEFAULT_OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "gemma2:2b")
DEFAULT_OLLAMA_HOST = os.getenv("OLLAMA_HOST", "http://localhost:11434")
DEFAULT_OLLAMA_TIMEOUT = int(os.getenv("OLLAMA_TIMEOUT", "600"))

# Elasticsearch
DEFAULT_ELASTIC_HOST = os.getenv("ELASTIC_HOST", "localhost")
DEFAULT_ELASTIC_PORT = int(os.getenv("ELASTIC_PORT", "9200"))
DEFAULT_ELASTIC_INDEX = os.getenv("ELASTIC_INDEX", "psb_docs")

# Evaluation
DEFAULT_SIMILARITY_THRESHOLD = float(os.getenv("SIMILARITY_THRESHOLD", "0.60"))
DEFAULT_TOP_K = int(os.getenv("TOP_K", "5"))



# EMBEDDING MODEL (SINGLETON)
class EmbeddingModel:
    """
    Singleton –∫–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å embeddings
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤–æ –≤—Å–µ–º –ø—Ä–æ–µ–∫—Ç–µ
    """
    
    _instance: Optional['EmbeddingModel'] = None
    _model: Optional[SentenceTransformer] = None
    
    def __new__(cls):
        """Singleton pattern - –æ–¥–∏–Ω —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–∞ –≤–µ—Å—å –ø—Ä–æ–µ–∫—Ç"""
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ (—Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑)"""
        if self._model is None:
            print(f"–ó–∞–≥—Ä—É–∑–∫–∞ embedding –º–æ–¥–µ–ª–∏: {DEFAULT_EMBEDDING_MODEL}")
            self._model = SentenceTransformer(DEFAULT_EMBEDDING_MODEL) 
            print("–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    def encode(self, texts, show_progress_bar: bool = False, convert_to_numpy: bool = True):
        """
        –°–æ–∑–¥–∞–Ω–∏–µ embeddings –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤
        
        Args:
            texts: –°—Ç—Ä–æ–∫–∞ –∏–ª–∏ —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫
            show_progress_bar: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä
            convert_to_numpy: –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ numpy array
            
        Returns:
            Numpy array —Å embeddings –∏–ª–∏ list
        """
        if self._model is None:
            raise RuntimeError("–ú–æ–¥–µ–ª—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
        
        embeddings = self._model.encode(
            texts,
            show_progress_bar=show_progress_bar,
            convert_to_numpy=convert_to_numpy
        )
        
        return embeddings
    
    def get_model(self) -> SentenceTransformer:
        """–ü–æ–ª—É—á–∏—Ç—å –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å SentenceTransformer"""
        if self._model is None:
            raise RuntimeError("–ú–æ–¥–µ–ª—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
        return self._model

# HELPER FUNCTION (–¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞)

def get_embedding_model() -> EmbeddingModel:
    """
    –ü–æ–ª—É—á–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä EmbeddingModel
    
    Usage:
        from package.config import get_embedding_model
        
        model = get_embedding_model()
        embedding = model.encode("—Ç–µ–∫—Å—Ç")
    """
    return EmbeddingModel()


# DATACLASS –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)

@dataclass
class ElasticsearchConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Elasticsearch"""
    host: str = DEFAULT_ELASTIC_HOST          
    port: int = DEFAULT_ELASTIC_PORT          
    index_name: str = DEFAULT_ELASTIC_INDEX
    
    def get_url(self) -> str:
        return f"http://{self.host}:{self.port}"


@dataclass
class OllamaConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Ollama"""
    host: str = DEFAULT_OLLAMA_HOST      
    model: str = DEFAULT_OLLAMA_MODEL    
    timeout: int = DEFAULT_OLLAMA_TIMEOUT


@dataclass
class EmbeddingConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Embeddings (—É—Å—Ç–∞—Ä–µ–ª–æ, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ get_embedding_model())"""
    model_name: str = DEFAULT_EMBEDDING_MODEL 


@dataclass
class EvaluationConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ—Ü–µ–Ω–∫–∏"""
    similarity_threshold: float = DEFAULT_SIMILARITY_THRESHOLD 
    top_k: int = DEFAULT_TOP_K                                 


# UNIFIED CONFIG (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)

class Config:
    """Unified configuration class"""
    
    # Ollama settings
    OLLAMA_HOST = DEFAULT_OLLAMA_HOST      
    OLLAMA_MODEL = DEFAULT_OLLAMA_MODEL    
    OLLAMA_TIMEOUT = DEFAULT_OLLAMA_TIMEOUT
    
    # Embeddings settings
    EMBEDDING_MODEL = DEFAULT_EMBEDDING_MODEL 
    
    # Evaluation settings
    SIMILARITY_THRESHOLD = DEFAULT_SIMILARITY_THRESHOLD 
    TOP_K = DEFAULT_TOP_K                               
    
    # Elasticsearch settings
    ELASTIC_HOST = DEFAULT_ELASTIC_HOST   
    ELASTIC_PORT = DEFAULT_ELASTIC_PORT   
    ELASTIC_INDEX = DEFAULT_ELASTIC_INDEX 
    
    # Paths
    DOCUMENTS_PATH = "data/documents"
    TESTSETS_PATH = "data/testsets"
    REPORTS_PATH = "data/reports"


    __all__ = [
    # –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
    'DEFAULT_EMBEDDING_MODEL',
    'DEFAULT_EMBEDDING_DIMS',
    'EMBEDDING_MODELS',      
    'DEFAULT_OLLAMA_MODEL',
    'DEFAULT_OLLAMA_HOST',
    'DEFAULT_OLLAMA_TIMEOUT',
    'DEFAULT_ELASTIC_HOST',
    'DEFAULT_ELASTIC_PORT',
    'DEFAULT_ELASTIC_INDEX',
    'DEFAULT_SIMILARITY_THRESHOLD',
    'DEFAULT_TOP_K',
    # –§—É–Ω–∫—Ü–∏–∏
    'get_embedding_model',
    'get_model_info',       
    # –ö–ª–∞—Å—Å—ã
    'EmbeddingModel',
    'Config',
    'ElasticsearchConfig',
    'OllamaConfig',
    'EmbeddingConfig',
    'EvaluationConfig',
]