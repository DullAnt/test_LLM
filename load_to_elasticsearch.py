"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ Elasticsearch

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç:
1. –ü–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –∫ Elasticsearch
2. –°–æ–∑–¥–∞–µ—Ç –∏–Ω–¥–µ–∫—Å —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
3. –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ data/documents/
4. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç .txt –∏ .md —Ñ–∞–π–ª—ã
"""

import sys
from pathlib import Path
from elasticsearch import Elasticsearch
from typing import List


def check_elasticsearch_connection(es_host: str = "localhost", es_port: int = 9200) -> Elasticsearch:
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Elasticsearch
    
    Args:
        es_host: –•–æ—Å—Ç Elasticsearch
        es_port: –ü–æ—Ä—Ç Elasticsearch
        
    Returns:
        Elasticsearch: –ö–ª–∏–µ–Ω—Ç Elasticsearch
    """
    print(f"\n[ES] –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Elasticsearch ({es_host}:{es_port})...")
    
    try:
        # –°–æ–∑–¥–∞—Ç—å –∫–ª–∏–µ–Ω—Ç
        es = Elasticsearch(
            [f"http://{es_host}:{es_port}"],
            verify_certs=False,
            request_timeout=30
        )
        
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
        if not es.ping():
            print("[ERROR] –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Elasticsearch!")
            print("\nüí° –ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å:")
            print("   1. –ó–∞–ø—É—Å—Ç–∏—Ç–µ: docker-compose up -d elasticsearch")
            print("   2. –ü–æ–¥–æ–∂–¥–∏—Ç–µ 30 —Å–µ–∫—É–Ω–¥")
            print("   3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ: curl http://localhost:9200")
            sys.exit(1)
        
        # –ü–æ–ª—É—á–∏—Ç—å –≤–µ—Ä—Å–∏—é
        info = es.info()
        version = info['version']['number']
        print(f"[ES] ‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ! (Elasticsearch {version})")
        
        return es
        
    except Exception as e:
        print(f"[ERROR] –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
        print("\nüí° –ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å:")
        print("   1. –ó–∞–ø—É—Å—Ç–∏—Ç–µ: docker-compose up -d elasticsearch")
        print("   2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏: docker logs test_llm_elasticsearch")
        sys.exit(1)


def create_index(es: Elasticsearch, index_name: str):
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
    
    Args:
        es: –ö–ª–∏–µ–Ω—Ç Elasticsearch
        index_name: –ù–∞–∑–≤–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
    """
    # –£–¥–∞–ª–∏—Ç—å –∏–Ω–¥–µ–∫—Å –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    if es.indices.exists(index=index_name):
        print(f"[ES] –£–¥–∞–ª–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ '{index_name}'...")
        es.indices.delete(index=index_name)
        print(f"[ES] ‚úÖ –ò–Ω–¥–µ–∫—Å —É–¥–∞–ª–µ–Ω")
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–Ω–¥–µ–∫—Å–∞
    index_settings = {
        "settings": {
            "number_of_shards": 1,      # –û–¥–Ω–∞ –Ω–æ–¥–∞ = –æ–¥–∏–Ω —à–∞—Ä–¥
            "number_of_replicas": 0,    # –ë–µ–∑ —Ä–µ–ø–ª–∏–∫ –¥–ª—è dev
            "analysis": {
                "analyzer": {
                    "russian": {
                        "type": "standard"
                    }
                }
            }
        },
        "mappings": {
            "properties": {
                "filename": {
                    "type": "keyword"        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                },
                "content": {
                    "type": "text",          # –ü–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫
                    "analyzer": "russian"
                },
                "path": {
                    "type": "keyword"
                },
                "chunks": {
                    "type": "text",          # –†–∞–∑–±–∏—Ç—ã–π –Ω–∞ chunks –∫–æ–Ω—Ç–µ–Ω—Ç
                    "analyzer": "russian"
                }
            }
        }
    }
    
    # –°–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å
    print(f"[ES] –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ '{index_name}'...")
    es.indices.create(index=index_name, body=index_settings)
    print(f"[ES] ‚úÖ –ò–Ω–¥–µ–∫—Å —Å–æ–∑–¥–∞–Ω")


def split_into_chunks(text: str, chunk_size: int = 500, overlap: int = 50) -> List[str]:
    """
    –†–∞–∑–±–∏—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ chunks —Å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º
    
    Args:
        text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
        chunk_size: –†–∞–∑–º–µ—Ä chunk –≤ —Å–∏–º–≤–æ–ª–∞—Ö
        overlap: –ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –º–µ–∂–¥—É chunks
        
    Returns:
        List[str]: –°–ø–∏—Å–æ–∫ chunks
    """
    # –†–∞–∑–±–∏—Ç—å –ø–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞–º
    paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]
    
    chunks = []
    current_chunk = ""
    
    for paragraph in paragraphs:
        # –ï—Å–ª–∏ –ø–∞—Ä–∞–≥—Ä–∞—Ñ + —Ç–µ–∫—É—â–∏–π chunk –º–µ–Ω—å—à–µ –ª–∏–º–∏—Ç–∞ - –¥–æ–±–∞–≤–∏—Ç—å
        if len(current_chunk) + len(paragraph) <= chunk_size:
            current_chunk += paragraph + "\n\n"
        else:
            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–µ–∫—É—â–∏–π chunk
            if current_chunk:
                chunks.append(current_chunk.strip())
            
            # –ù–∞—á–∞—Ç—å –Ω–æ–≤—ã–π chunk
            current_chunk = paragraph + "\n\n"
    
    # –î–æ–±–∞–≤–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π chunk
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    return chunks


def find_documents(docs_path: str) -> List[Path]:
    """
    –ù–∞–π—Ç–∏ –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –ø–∞–ø–∫–µ
    
    Args:
        docs_path: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
        
    Returns:
        List[Path]: –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º
    """
    print(f"\n[ES] –ü–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ '{docs_path}'...")
    
    docs_dir = Path(docs_path)
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –ø–∞–ø–∫–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    if not docs_dir.exists():
        print(f"[ERROR] –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {docs_path}")
        print("\nüí° –ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å:")
        print(f"   1. –°–æ–∑–¥–∞–π—Ç–µ –ø–∞–ø–∫—É: mkdir {docs_path}")
        print(f"   2. –ü–æ–ª–æ–∂–∏—Ç–µ —Ç—É–¥–∞ .txt –∏–ª–∏ .md —Ñ–∞–π–ª—ã")
        sys.exit(1)
    
    # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
    supported_formats = ['.txt', '.md']
    
    # –ù–∞–π—Ç–∏ –≤—Å–µ —Ñ–∞–π–ª—ã
    files = []
    for ext in supported_formats:
        files.extend(docs_dir.rglob(f'*{ext}'))
    
    if not files:
        print(f"[WARNING] –ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ '{docs_path}'")
        print(f"\nüí° –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: {', '.join(supported_formats)}")
        print(f"üí° –ü–æ–ª–æ–∂–∏—Ç–µ —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫—É: {docs_path}")
        sys.exit(1)
    
    print(f"[ES] ‚úÖ –ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(files)}")
    
    # –ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫
    for i, file in enumerate(files, 1):
        size_kb = file.stat().st_size / 1024
        print(f"     {i}. {file.name} ({size_kb:.1f} KB)")
    
    return files


def load_documents(es: Elasticsearch, index_name: str, files: List[Path]):
    """
    –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ Elasticsearch
    
    Args:
        es: –ö–ª–∏–µ–Ω—Ç Elasticsearch
        index_name: –ù–∞–∑–≤–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
        files: –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
    """
    print(f"\n[ES] –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å '{index_name}'...")
    
    success_count = 0
    error_count = 0
    
    for i, file_path in enumerate(files, 1):
        try:
            # –ü—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–µ –ø—É—Å—Ç–æ–π
            if not content.strip():
                print(f"[{i}/{len(files)}] ‚ö†Ô∏è  {file_path.name} - –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                error_count += 1
                continue
            
            # –†–∞–∑–±–∏—Ç—å –Ω–∞ chunks
            chunks = split_into_chunks(content)
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç
            document = {
                'filename': file_path.name,
                'content': content,
                'path': str(file_path),
                'chunks': chunks
            }
            
            # –ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å
            es.index(index=index_name, body=document)
            
            print(f"[{i}/{len(files)}] ‚úÖ {file_path.name} ({len(content)} —Å–∏–º–≤–æ–ª–æ–≤, {len(chunks)} chunks)")
            success_count += 1
            
        except UnicodeDecodeError:
            print(f"[{i}/{len(files)}] ‚ùå {file_path.name} - –æ—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏")
            error_count += 1
        except Exception as e:
            print(f"[{i}/{len(files)}] ‚ùå {file_path.name} - {e}")
            error_count += 1
    
    # –û–±–Ω–æ–≤–∏—Ç—å –∏–Ω–¥–µ–∫—Å (flush changes)
    print(f"\n[ES] –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞...")
    es.indices.refresh(index=index_name)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    doc_count = es.count(index=index_name)['count']
    
    print(f"\n" + "=" * 80)
    print(f"[ES] ‚úÖ –ó–ê–ì–†–£–ó–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!")
    print("=" * 80)
    print(f"–£—Å–ø–µ—à–Ω–æ:      {success_count}/{len(files)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    print(f"–û—à–∏–±–∫–∏:       {error_count}/{len(files)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    print(f"–í –∏–Ω–¥–µ–∫—Å–µ:    {doc_count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    print(f"–ò–Ω–¥–µ–∫—Å:       {index_name}")
    print("=" * 80)
    
    if success_count == 0:
        print("\n[ERROR] –ù–∏ –æ–¥–∏–Ω –¥–æ–∫—É–º–µ–Ω—Ç –Ω–µ –±—ã–ª –∑–∞–≥—Ä—É–∂–µ–Ω!")
        sys.exit(1)


def verify_index(es: Elasticsearch, index_name: str):
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω–¥–µ–∫—Å–∞ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏
    
    Args:
        es: –ö–ª–∏–µ–Ω—Ç Elasticsearch
        index_name: –ù–∞–∑–≤–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
    """
    print(f"\n[ES] –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω–¥–µ–∫—Å–∞ '{index_name}'...")
    
    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    doc_count = es.count(index=index_name)['count']
    print(f"[ES] –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å–µ: {doc_count}")
    
    # –†–∞–∑–º–µ—Ä –∏–Ω–¥–µ–∫—Å–∞
    stats = es.indices.stats(index=index_name)
    size_bytes = stats['indices'][index_name]['total']['store']['size_in_bytes']
    size_mb = size_bytes / (1024 * 1024)
    print(f"[ES] –†–∞–∑–º–µ—Ä –∏–Ω–¥–µ–∫—Å–∞: {size_mb:.2f} MB")
    
    # –ü—Ä–∏–º–µ—Ä –ø–æ–∏—Å–∫–∞
    print(f"\n[ES] –¢–µ—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫...")
    try:
        result = es.search(
            index=index_name,
            body={
                "query": {"match_all": {}},
                "size": 1
            }
        )
        
        if result['hits']['total']['value'] > 0:
            first_doc = result['hits']['hits'][0]['_source']
            print(f"[ES] ‚úÖ –ü–µ—Ä–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç: {first_doc['filename']}")
            print(f"[ES] ‚úÖ –ö–æ–Ω—Ç–µ–Ω—Ç: {first_doc['content'][:100]}...")
        else:
            print(f"[ES] ‚ö†Ô∏è  –î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    except Exception as e:
        print(f"[ES] ‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    print("=" * 80)
    print("–ó–ê–ì–†–£–ó–ö–ê –î–û–ö–£–ú–ï–ù–¢–û–í –í ELASTICSEARCH")
    print("=" * 80)
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã (–º–æ–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å)
    ES_HOST = "localhost"
    ES_PORT = 9200
    ES_INDEX = "psb_docs"
    DOCS_PATH = "data/documents"
    
    # 1. –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Elasticsearch
    es = check_elasticsearch_connection(ES_HOST, ES_PORT)
    
    # 2. –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
    create_index(es, ES_INDEX)
    
    # 3. –ü–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    files = find_documents(DOCS_PATH)
    
    # 4. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    load_documents(es, ES_INDEX, files)
    
    # 5. –ü—Ä–æ–≤–µ—Ä–∫–∞
    verify_index(es, ES_INDEX)
    
    # –ì–æ—Ç–æ–≤–æ!
    print(f"\n" + "=" * 80)
    print("‚úÖ –ì–û–¢–û–í–û! –¢–µ–ø–µ—Ä—å –º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å:")
    print("   python main.py --max-questions 5")
    print("=" * 80)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n[INFO] –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(0)
    except Exception as e:
        print(f"\n[ERROR] –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)