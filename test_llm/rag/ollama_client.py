"""
Ollama Client –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –ª–æ–∫–∞–ª—å–Ω—ã–º LLM
"""

import requests
import json
import re
from typing import List, Dict, Optional


class OllamaClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Ollama API"""
    
    def __init__(self, host: str = "http://localhost:11434", model: str = "llama3", timeout: int = 300):
        """
        Args:
            host: URL Ollama —Å–µ—Ä–≤–µ—Ä–∞
            model: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
            timeout: –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        """
        self.host = host.rstrip('/')
        self.model = model
        self.timeout = timeout
        self._ollama_version = None
        
        # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫ –ø–æ –ø–æ—Ä—Ç—É
        self.source = self._detect_source()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
        if self.check_connection():
            print(f"[OLLAMA] ‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–æ ({self.model})")
            print(f"         –ò—Å—Ç–æ—á–Ω–∏–∫: {self.source}")
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
            if not self._check_model_available():
                print(f"[WARNING] ‚ö†Ô∏è –ú–æ–¥–µ–ª—å {self.model} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
                self._print_available_models()
        else:
            print(f"[ERROR] ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Ollama: {self.host}")
            self._print_connection_help()
    
    def _detect_source(self) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫ Ollama –ø–æ –ø–æ—Ä—Ç—É"""
        if ":11434" in self.host or self.host.endswith("11434"):
            return "–õ–æ–∫–∞–ª—å–Ω–∞—è Ollama (–ø–æ—Ä—Ç 11434)"
        elif ":11435" in self.host or self.host.endswith("11435"):
            return "Docker Ollama (–ø–æ—Ä—Ç 11435)"
        else:
            return f"–ö–∞—Å—Ç–æ–º–Ω—ã–π —Å–µ—Ä–≤–µ—Ä ({self.host})"
    
    def check_connection(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama"""
        try:
            response = requests.get(f"{self.host}/api/tags", timeout=5)
            if response.status_code == 200:
                # –ü–æ–ª—É—á–∏—Ç—å –≤–µ—Ä—Å–∏—é Ollama
                try:
                    version_response = requests.get(f"{self.host}/api/version", timeout=2)
                    if version_response.status_code == 200:
                        self._ollama_version = version_response.json().get('version', 'unknown')
                except:
                    pass
                return True
            return False
        except requests.exceptions.ConnectionError:
            return False
        except requests.exceptions.Timeout:
            print(f"[ERROR] –¢–∞–π–º–∞—É—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama (>{5}s)")
            return False
        except Exception as e:
            print(f"[ERROR] –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama: {e}")
            return False
    
    def _check_model_available(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
        try:
            response = requests.get(f"{self.host}/api/tags", timeout=5)
            if response.status_code == 200:
                data = response.json()
                models = data.get('models', [])
                return any(m.get('name', '').startswith(self.model) for m in models)
            return False
        except:
            return False
    
    def _print_available_models(self):
        """–í—ã–≤–æ–¥ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            response = requests.get(f"{self.host}/api/tags", timeout=5)
            if response.status_code == 200:
                data = response.json()
                models = data.get('models', [])
                
                if models:
                    print("\n[INFO] üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:")
                    for m in models:
                        name = m.get('name', 'unknown')
                        size_gb = m.get('size', 0) / (1024**3)
                        print(f"       - {name} ({size_gb:.1f}GB)")
                    
                    print(f"\n[TIP] üí° –ó–∞–≥—Ä—É–∑–∏—Ç–µ –Ω—É–∂–Ω—É—é –º–æ–¥–µ–ª—å:")
                    if ":11435" in self.host:
                        print(f"       docker exec test_llm_ollama ollama pull {self.model}")
                    else:
                        print(f"       ollama pull {self.model}")
                else:
                    print("\n[WARNING] –ù–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π!")
                    self._print_install_model_help()
        except:
            pass
    
    def _print_install_model_help(self):
        """–ü–æ–¥—Å–∫–∞–∑–∫–∞ –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ –º–æ–¥–µ–ª–∏"""
        print("\n[TIP] üí° –ö–∞–∫ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –º–æ–¥–µ–ª—å:")
        if ":11435" in self.host:
            # Docker Ollama
            print("       1. –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ: python setup_ollama.py")
            print(f"       2. –í—Ä—É—á–Ω—É—é: docker exec test_llm_ollama ollama pull {self.model}")
        else:
            # –õ–æ–∫–∞–ª—å–Ω–∞—è Ollama
            print(f"       ollama pull {self.model}")
            print("       –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ: qwen2.5:7b, gemma2:9b, gemma2:2b")
    
    def _print_connection_help(self):
        """–ü–æ–¥—Å–∫–∞–∑–∫–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è"""
        print("\n[TIP] üí° –ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å:")
        
        if ":11434" in self.host:
            # –õ–æ–∫–∞–ª—å–Ω–∞—è Ollama
            print("       1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω–∞:")
            print("          ollama list")
            print("       2. –ü–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: https://ollama.com/download")
            print("       3. –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Docker:")
            print("          python main.py --ollama-host http://localhost:11435")
        
        elif ":11435" in self.host:
            # Docker Ollama
            print("       1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —á—Ç–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –∑–∞–ø—É—â–µ–Ω:")
            print("          docker ps | grep ollama")
            print("       2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä:")
            print("          docker-compose up -d ollama")
            print("       3. –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ª–æ–∫–∞–ª—å–Ω—É—é Ollama:")
            print("          python main.py --ollama-host http://localhost:11434")
        else:
            print(f"       –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Å–µ—Ä–≤–µ—Ä–∞: {self.host}")
    
    def get_info(self) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± Ollama"""
        info = {
            "host": self.host,
            "model": self.model,
            "source": self.source,
            "connected": self.check_connection(),
            "version": self._ollama_version
        }
        
        try:
            response = requests.get(f"{self.host}/api/tags", timeout=5)
            if response.status_code == 200:
                data = response.json()
                info["available_models"] = [m.get('name') for m in data.get('models', [])]
        except:
            info["available_models"] = []
        
        return info
    
    def generate(self, question: str, context: List[str]) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        
        Args:
            question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            context: –°–ø–∏—Å–æ–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤
            
        Returns:
            –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
        """
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
        if context:
            context_text = "\n\n".join(context)
            prompt = f"""–¢—ã —ç–∫—Å–ø–µ—Ä—Ç-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –±–∞–Ω–∫–∞. –û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –∫–ª–∏–µ–Ω—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.

–ü–†–ê–í–ò–õ–ê:
1. –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–∏–∂–µ
2. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ —Ç–æ—á–Ω–æ (1-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
3. –ï—Å–ª–∏ –Ω—É–∂–µ–Ω —Ä–∞—Å—á–µ—Ç - –ø–æ—Å—á–∏—Ç–∞–π –∏ –¥–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ —á–∏—Å–ª–æ
4. –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å —Ç–æ—á–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞ –∏–ª–∏ –ø—Ä–æ—Ü–µ–Ω—Ç—ã - –∏—Å–ø–æ–ª—å–∑—É–π –∏—Ö
5. –ù–ï –≥–æ–≤–æ—Ä–∏ "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç" –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
6. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π markdown —Ä–∞–∑–º–µ—Ç–∫—É (–∂–∏—Ä–Ω—ã–π, —Å–ø–∏—Å–∫–∏ –∏ —Ç.–¥.)
7. –ö–æ–ø–∏—Ä—É–π —Ç–æ—á–Ω—ã–µ —á–∏—Å–ª–∞ –∏ —Ñ–æ—Ä–º—É–ª—ã –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

–ü–†–ò–ú–ï–†–´:

–í–æ–ø—Ä–æ—Å: –ü–æ—Å—á–∏—Ç–∞–π –∫–æ–º–∏—Å—Å–∏—é –µ—Å–ª–∏ —è –ø—Ä–µ–≤—ã—à—É –ª–∏–º–∏—Ç –Ω–∞ 20000
–ö–æ–Ω—Ç–µ–∫—Å—Ç: "50 000‚ÇΩ - –±–µ—Å–ø–ª–∞—Ç–Ω–æ (0%) 20 000‚ÇΩ - –∫–æ–º–∏—Å—Å–∏—è 0,8% = 160‚ÇΩ"
–û—Ç–≤–µ—Ç: 50 000‚ÇΩ - –±–µ—Å–ø–ª–∞—Ç–Ω–æ (0%), 20 000‚ÇΩ - –∫–æ–º–∏—Å—Å–∏—è 0,8% = 160‚ÇΩ. –ò—Ç–æ–≥–æ –∫–æ–º–∏—Å—Å–∏—è: 160‚ÇΩ

–í–æ–ø—Ä–æ—Å: –ú–æ–≥—É –ª–∏ —è —Å–Ω—è—Ç—å –±–µ–∑ –∫–æ–º–∏—Å—Å–∏–∏ –≤ –í–¢–ë?
–ö–æ–Ω—Ç–µ–∫—Å—Ç: "–î–∞, 0% –∫–æ–º–∏—Å—Å–∏–∏ –¥–ª—è –∫–∞—Ä—Ç –ú–∏—Ä –≤ –±–∞–Ω–∫–æ–º–∞—Ç–∞—Ö –í–¢–ë"
–û—Ç–≤–µ—Ç: –î–∞, 0% –∫–æ–º–∏—Å—Å–∏–∏ –¥–ª—è –∫–∞—Ä—Ç –ø–ª–∞—Ç–µ–∂–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –ú–∏—Ä –≤ –±–∞–Ω–∫–æ–º–∞—Ç–∞—Ö –í–¢–ë.

–í–æ–ø—Ä–æ—Å: –í —á–µ–º —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É –∫–∞—Ä—Ç–∞–º–∏?
–ö–æ–Ω—Ç–µ–∫—Å—Ç: "–û—Å–Ω–æ–≤–Ω–∞—è –∫–∞—Ä—Ç–∞ –≤—ã–ø—É—Å–∫–∞–µ—Ç—Å—è –Ω–∞ –≤–ª–∞–¥–µ–ª—å—Ü–∞ —Å—á–µ—Ç–∞. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∫–∞—Ä—Ç–∞ –≤—ã–ø—É—Å–∫–∞–µ—Ç—Å—è –Ω–∞ –¥—Ä—É–≥–æ–µ –ª–∏—Ü–æ."
–û—Ç–≤–µ—Ç: –û—Å–Ω–æ–≤–Ω–∞—è –∫–∞—Ä—Ç–∞ –≤—ã–ø—É—Å–∫–∞–µ—Ç—Å—è –Ω–∞ –≤–ª–∞–¥–µ–ª—å—Ü–∞ —Å—á–µ—Ç–∞, –∞ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∫–∞—Ä—Ç–∞ –≤—ã–ø—É—Å–∫–∞–µ—Ç—Å—è –Ω–∞ –¥—Ä—É–≥–æ–µ –ª–∏—Ü–æ.

–ö–û–ù–¢–ï–ö–°–¢:
{context_text}

–í–û–ü–†–û–°: {question}

–û–¢–í–ï–¢:"""
        else:
            prompt = f"""–û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–≤–æ–∏—Ö –∑–Ω–∞–Ω–∏–π –æ –±–∞–Ω–∫–æ–≤—Å–∫–∏—Ö –ø—Ä–æ–¥—É–∫—Ç–∞—Ö.

–í–æ–ø—Ä–æ—Å: {question}

–û—Ç–≤–µ—Ç:"""
        
        try:
            # –ó–∞–ø—Ä–æ—Å –∫ Ollama API
            response = requests.post(
                f"{self.host}/api/generate",
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.1,  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
                        "top_p": 0.9,
                        "top_k": 40,
                        "num_predict": 200,  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã –æ—Ç–≤–µ—Ç–∞
                        "repeat_penalty": 1.1,
                    }
                },
                timeout=self.timeout
            )
            
            if response.status_code == 200:
                result = response.json()
                answer = result.get('response', '').strip()
                
                # –û—á–∏—Å—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –æ—Ç markdown
                answer = self._clean_response(answer)
                
                return answer
            
            elif response.status_code == 404:
                error_msg = f"–ú–æ–¥–µ–ª—å {self.model} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
                print(f"[ERROR] {error_msg}")
                self._print_available_models()
                return f"–û—à–∏–±–∫–∞: {error_msg}"
            
            else:
                print(f"[ERROR] Ollama –≤–µ—Ä–Ω—É–ª –∫–æ–¥ {response.status_code}")
                try:
                    error_data = response.json()
                    error_detail = error_data.get('error', 'Unknown error')
                    print(f"[ERROR] –î–µ—Ç–∞–ª–∏: {error_detail}")
                except:
                    pass
                return "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞"
                
        except requests.exceptions.Timeout:
            print(f"[ERROR] –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ –∫ Ollama (>{self.timeout}s)")
            print(f"[TIP] –£–≤–µ–ª–∏—á—å—Ç–µ —Ç–∞–π–º–∞—É—Ç: --timeout 900")
            return "–¢–∞–π–º–∞—É—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞"
        
        except requests.exceptions.ConnectionError:
            print(f"[ERROR] –ü–æ—Ç–µ—Ä—è–Ω–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Ollama")
            self._print_connection_help()
            return "–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å Ollama"
        
        except Exception as e:
            print(f"[ERROR] –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            return "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞"
    
    def _clean_response(self, text: str) -> str:
        """–û—á–∏—Å—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –æ—Ç markdown —Ä–∞–∑–º–µ—Ç–∫–∏"""
        # –£–±—Ä–∞—Ç—å markdown
        text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text)  # **–∂–∏—Ä–Ω—ã–π**
        text = re.sub(r'\*([^*]+)\*', r'\1', text)      # *–∫—É—Ä—Å–∏–≤*
        text = re.sub(r'^#{1,6}\s+', '', text, flags=re.MULTILINE)  # –∑–∞–≥–æ–ª–æ–≤–∫–∏
        text = re.sub(r'^\d+\.\s+', '', text, flags=re.MULTILINE)   # —Å–ø–∏—Å–∫–∏ 1. 2. 3.
        text = re.sub(r'^[-‚Ä¢]\s+', '', text, flags=re.MULTILINE)    # –±—É–ª–ª–µ—Ç—ã - –∏ ‚Ä¢
        
        # –£–±—Ä–∞—Ç—å –ø—Ä–µ—Ñ–∏–∫—Å—ã –µ—Å–ª–∏ LLM –∏—Ö –ø–æ–≤—Ç–æ—Ä–∏–ª
        text = re.sub(r'^(–û—Ç–≤–µ—Ç:|–û–¢–í–ï–¢:)\s*', '', text, flags=re.IGNORECASE)
        text = re.sub(r'^(–ö—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç:|–ö–†–ê–¢–ö–ò–ô –û–¢–í–ï–¢:)\s*', '', text, flags=re.IGNORECASE)
        
        return text.strip()
    
    def __repr__(self):
        status = "‚úÖ Connected" if self.check_connection() else "‚ùå Disconnected"
        return f"OllamaClient(host='{self.host}', model='{self.model}', status={status})"